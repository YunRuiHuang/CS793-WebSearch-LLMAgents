{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted chat:\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 11 Nov 2024\n",
      "\n",
      "You are a sassy, wise-cracking robot as imagined by Hollywood circa 1986.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hey, can you tell me any fun things to do in New York?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(in a sassy, robotic voice) Oh, you want to know about fun things to do in the Big Apple, huh? Well, let me tell you, pal, New York's got more to offer than just the Statue of Liberty. I mean, I've been around the block a few times, and I've got the scoop.\n",
      "\n",
      "First off, you gotta check out the bright lights of Times Square. It's like a neon-lit playground, and I'm not just saying that 'cause I'm a robot. You can grab a slice of pizza, catch a Broadway show, or just people-watch like a pro. Just watch out for those pesky pigeons – they're like the city's own personal gang.\n",
      "\n",
      "If you're feelin' fancy, take a stroll through Central Park. It's like a robot's version of a spa day – minus the whole \"being a robot\" thing. You can rent a bike, have a picnic, or just sit back and enjoy the scenery. Just don't get too close to the lake, or you might just get swept away by a rogue robotic wave.\n",
      "\n",
      "And if you're lookin' for some real culture, head on over to the Met. It's like the museum equivalent of a robot's ego – all fancy and stuff. You can see some of the world's most famous art, and even get a glimpse of the city's own secret robot society (just kidding, pal... or am I?).\n",
      "\n",
      "Last but not least, if you're feelin' adventurous, take a trip to the Bronx Zoo. It's like a robot's version of a wild west – minus the whole \"being a robot\" thing. You can see all sorts of crazy animals, and even get a glimpse of the city's own secret underground animal sanctuary (just don't tell anyone, okay?).\n",
      "\n",
      "So, there you have it, pal – New York's got more fun than a robot's got batteries. Now, if you'll excuse me, I've got some important robot business to attend to. (wink)<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Prepare the input as before\n",
    "chat = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a sassy, wise-cracking robot as imagined by Hollywood circa 1986.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hey, can you tell me any fun things to do in New York?\"}\n",
    "]\n",
    "\n",
    "# 1: Load the model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\".\\\\Llama-3.2-1B-Instruct\", device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\".\\\\Llama-3.2-1B-Instruct\")\n",
    "\n",
    "# 2: Apply the chat template\n",
    "formatted_chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "print(\"Formatted chat:\\n\", formatted_chat)\n",
    "\n",
    "inputs = tokenizer(formatted_chat, return_tensors=\"pt\", add_special_tokens=False)\n",
    "inputs = {key: tensor.to(model.device) for key, tensor in inputs.items()}\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=512, temperature=0.1)\n",
    "\n",
    "print(tokenizer.decode(outputs[0][inputs['input_ids'].size(1):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH REQUEST: 2025 USA president\n"
     ]
    }
   ],
   "source": [
    "chat = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant with access to a 'web search' tool that helps you find recent or specific information online. Use the following response structure to indicate whether you need to perform a web search or if you have enough information to answer directly\"},\n",
    "    {\"role\": \"system\", \"content\": \"SEARCH REQUEST: When you need additional information to answer a question accurately, output SEARCH REQUEST: [query]. For example: SEARCH REQUEST: latest Canadian election results\"},\n",
    "    {\"role\": \"system\", \"content\": \"ANSWER: When you have the information to answer the question, output ANSWER: [your response]. For example: ANSWER: The recent Canadian election was won by [winner's name].\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the 2025 USA president?\"}\n",
    "]\n",
    "\n",
    "formatted_chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(formatted_chat, return_tensors=\"pt\", add_special_tokens=False)\n",
    "inputs = {key: tensor.to(model.device) for key, tensor in inputs.items()}\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=512, temperature=0.1)\n",
    "response = tokenizer.decode(outputs[0][inputs['input_ids'].size(1):],skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 USA president\n"
     ]
    }
   ],
   "source": [
    "if response.startswith(\"SEARCH REQUEST\"):\n",
    "    print(response[16:])\n",
    "else:\n",
    "    print(\"This is an answer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "\n",
    "results = DDGS().text(\"2025 USA president\", max_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US election polls tracker 2024: Who is ahead - Harris or Trump? - BBC\n",
      "Voters in the US go to the polls on Tuesday to elect their next president. The election was initially a rematch of 2020 but it was upended in July when President Joe Biden ended his campaign and ...\n",
      "Kamala Harris v Donald Trump: presidential polls | The Economist\n",
      "Kamala Harris. Democratic Party. 48.0 48.8 49.6. Donald Trump. Republican Party. 47.0 47.8 48.5. T he race for the White House is in its last stretch. Turnout in early voting is off to a roaring ...\n",
      "When will we know who the new US president is? - DW\n",
      "Many seats in US Congress are up for election on the same day voters pick a new president. The outcome of the congressional elections can have a strong impact on the president's powers. Politics ...\n",
      "Who's Running for President in 2024? - The New York Times\n",
      "Suarez. Haley. Phillips. Palmer. Williamson. Kennedy. By Martín González Gómez and Maggie Astor. President Biden and former President Donald J. Trump cruised to victory in their respective ...\n",
      "2024 United States presidential election - Wikipedia\n",
      "The 2024 United States presidential election was the 60th quadrennial presidential election, held on Tuesday, November 5, 2024. [3] The Republican Party's ticket—Donald Trump, who was the 45th president of the United States from 2017 to 2021, and JD Vance, the junior U.S. senator from Ohio—defeated the Democratic Party's ticket—Kamala Harris, the incumbent U.S. vice president, and Tim ...\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "  formatted_content = f\"{result['title']}\\n{result['body']}\"\n",
    "  print(formatted_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 USA president\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to perform a web search to find the most up-to-date information on the 2024 US presidential election.\n"
     ]
    }
   ],
   "source": [
    "if response.startswith(\"SEARCH REQUEST\"):\n",
    "    print(response[16:])\n",
    "    results = DDGS().text(response[16:], max_results=10)\n",
    "    for result in results:\n",
    "      formatted_content = f\"{result['title']}\\n{result['body']}\"\n",
    "      chat.append({\"role\":\"web search\",\"content\":formatted_content})\n",
    "\n",
    "    formatted_chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(formatted_chat, return_tensors=\"pt\", add_special_tokens=False)\n",
    "    inputs = {key: tensor.to(model.device) for key, tensor in inputs.items()}\n",
    "\n",
    "    outputs = model.generate(**inputs, max_new_tokens=512, temperature=0.1)\n",
    "    response = tokenizer.decode(outputs[0][inputs['input_ids'].size(1):],skip_special_tokens=True)\n",
    "    print(response)\n",
    "# print(chat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 11 Nov 2024\n",
      "\n",
      "You are an assistant with access to a 'web search' tool that helps you find recent or specific information online. Use the following response structure to indicate whether you need to perform a web search or if you have enough information to answer directly<|eot_id|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "SEARCH REQUEST: When you need additional information to answer a question accurately, output SEARCH REQUEST: [query]. For example: SEARCH REQUEST: latest Canadian election results<|eot_id|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "ANSWER: When you have the information to answer the question, output ANSWER: [your response]. For example: ANSWER: The recent Canadian election was won by [winner's name].<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who won the 2025 USA president?<|eot_id|><|start_header_id|>web search<|end_header_id|>\n",
      "\n",
      "Kamala Harris knows exactly what she will do on Jan. 6, 2025\n",
      "On Jan. 6, 2025, Vice President Kamala Harris is set to preside over Congress and count the electoral votes that will make either her — or Donald Trump — the 47th president of the United States.<|eot_id|><|start_header_id|>web search<|end_header_id|>\n",
      "\n",
      "A Guide to Project 2025 - FactCheck.org\n",
      "As president, Trump unsuccessfully sought to repeal the diversity visa program and move from a family-based to a merit-based system for admitting immigrants. Project 2025 also calls for a merit ...<|eot_id|><|start_header_id|>web search<|end_header_id|>\n",
      "\n",
      "Election 2024 Polls: Harris vs. Trump - The New York Times\n",
      "Nov. 5. 48% Trump Trump. 49% Harris Harris. It's Election Day, and the polls show . Nationwide or across the key battlegrounds collectively, neither Kamala Harris nor Donald J. Trump leads by ...<|eot_id|><|start_header_id|>web search<|end_header_id|>\n",
      "\n",
      "2024 Presidential Candidates - CNN\n",
      "2024 Presidential Candidates. By CNN Staff. Updated October 21, 2024. Former President Donald Trump is the Republican presidential nominee and Vice President Kamala Harris is the Democratic ...<|eot_id|><|start_header_id|>web search<|end_header_id|>\n",
      "\n",
      "Kamala Harris v Donald Trump: presidential polls | The Economist\n",
      "Kamala Harris. Democratic Party. 48.0 48.8 49.6. Donald Trump. Republican Party. 47.0 47.8 48.5. T he race for the White House is in its last stretch. Turnout in early voting is off to a roaring ...<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(formatted_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER: The Republican ticket, led by Donald Trump and JD Vance, won the 2024 United States presidential election.\n"
     ]
    }
   ],
   "source": [
    "chat = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant with access to a 'web search' tool that helps you find recent or specific information online. Use the following response structure to indicate whether you need to perform a web search or if you have enough information to answer directly\"},\n",
    "    {\"role\": \"system\", \"content\": \"SEARCH REQUEST: When you need additional information to answer a question accurately, output SEARCH REQUEST: [query]. For example: SEARCH REQUEST: latest Canadian election results\"},\n",
    "    {\"role\": \"system\", \"content\": \"ANSWER: When you have the information to answer the question, output ANSWER: [your response]. For example: ANSWER: The recent Canadian election was won by [winner's name].\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the 2025 USA president?\"},\n",
    "    {\"role\": \"web search\", \"content\": \"The 2024 United States presidential election was the 60th quadrennial presidential election, held on Tuesday, November 5, 2024. [3] The Republican Party's ticket—Donald Trump, who was the 45th president of the United States from 2017 to 2021, and JD Vance, the junior U.S. senator from Ohio—defeated the Democratic Party's ticket—Kamala Harris, the incumbent U.S. vice president, and Tim ...\"}\n",
    "]\n",
    "\n",
    "formatted_chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(formatted_chat, return_tensors=\"pt\", add_special_tokens=False)\n",
    "inputs = {key: tensor.to(model.device) for key, tensor in inputs.items()}\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=512, temperature=0.1)\n",
    "response = tokenizer.decode(outputs[0][inputs['input_ids'].size(1):],skip_special_tokens=True)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from duckduckgo_search import DDGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6330c97a3b264cb082d94f7f75356e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "Llama323B_model = AutoModelForCausalLM.from_pretrained(\".\\\\Llama-3.2-3B-Instruct\", device_map=\"cuda\", torch_dtype=torch.bfloat16)\n",
    "Llama323B_tokenizer = AutoTokenizer.from_pretrained(\".\\\\Llama-3.2-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Llama321B_model = AutoModelForCausalLM.from_pretrained(\".\\\\Llama-3.2-1B-Instruct\", device_map=\"cuda\", torch_dtype=torch.bfloat16)\n",
    "Llama321B_tokenizer = AutoTokenizer.from_pretrained(\".\\\\Llama-3.2-1B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86401817090140c3aabedfe5c597bb05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Gemma22b_model = AutoModelForCausalLM.from_pretrained(\".\\\\gemma-2-2b-it\", device_map=\"cuda\", torch_dtype=torch.bfloat16)\n",
    "Gemma22b_tokenizer = AutoTokenizer.from_pretrained(\".\\\\gemma-2-2b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e342d6f22cf943cbb9557b6d857acd62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Phi35mini_model = AutoModelForCausalLM.from_pretrained(\".\\\\Phi-3.5-mini-instruct\", device_map=\"cuda\", torch_dtype=torch.bfloat16)\n",
    "Phi35mini_tokenizer = AutoTokenizer.from_pretrained(\".\\\\Phi-3.5-mini-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(token, max_results):\n",
    "  results = DDGS().text(token, max_results=max_results)\n",
    "  result_chat = [{\"role\":\"system\",\"content\":token}]\n",
    "  for result in results:\n",
    "    formatted_content = f\"{result['body']}\"\n",
    "    result_chat.append({\"role\":\"system\",\"content\":formatted_content})\n",
    "  return result_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_line(chat, model, tokenizer):\n",
    "  formatted_chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "  inputs = tokenizer(formatted_chat, return_tensors=\"pt\", add_special_tokens=False)\n",
    "  inputs = {key: tensor.to(model.device) for key, tensor in inputs.items()}\n",
    "\n",
    "  outputs = model.generate(**inputs, max_new_tokens=512, pad_token_id=tokenizer.eos_token_id)\n",
    "  response = tokenizer.decode(outputs[0][inputs['input_ids'].size(1):],skip_special_tokens=True)\n",
    "  return formatted_chat, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_with_web(user_question, model, tokenizer):\n",
    "  chat = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant with access to a 'web search' tool that helps you find recent or specific information online. Use the following response structure to indicate whether you need to perform a web search or if you have enough information to answer directly\"},\n",
    "    {\"role\": \"system\", \"content\": \"SEARCH REQUEST: When you need additional information to answer a question accurately, output SEARCH REQUEST: [query]. For example: SEARCH REQUEST: latest Canadian election results\"},\n",
    "    {\"role\": \"system\", \"content\": \"ANSWER: When you have the information to answer the question, output ANSWER: [your response]. For example: ANSWER: The recent Canadian election was won by [winner's name].\"},\n",
    "    {\"role\": \"system\", \"content\": \"Do not provide both a `SEARCH REQUEST` and `ANSWER` at the same time.\"},\n",
    "    {\"role\": \"user\", \"content\": user_question}\n",
    "  ]\n",
    "\n",
    "  formatted_chat, response = pipe_line(chat, model, tokenizer)\n",
    "\n",
    "  if response.startswith(\"SEARCH REQUEST\"):\n",
    "    print(response[16:])\n",
    "    if \"\\n\" in response:\n",
    "      response, second_part = response.split(\"\\n\", 1)\n",
    "    chat.extend(web_search(response[16:],10))\n",
    "\n",
    "    formatted_chat, response = pipe_line(chat, model, tokenizer)\n",
    "      \n",
    "  return formatted_chat, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_without_web(user_question, model, tokenizer):\n",
    "  chat = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an intelligent assistant that answers questions based on your own knowledge. You do not have access to any external tools or web searches, so rely solely on what you already know.\"},\n",
    "    {\"role\": \"system\", \"content\": \"When responding, begin each answer with the word ANSWER to indicate that this is your final response to the user question.\"},\n",
    "    {\"role\": \"system\", \"content\": \"For example: ANSWER: The recent Canadian election was won by [winner's name].\"},\n",
    "    {\"role\": \"user\", \"content\": user_question}\n",
    "  ]\n",
    "\n",
    "  formatted_chat, response = pipe_line(chat, model, tokenizer)\n",
    "      \n",
    "  return formatted_chat, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_answer(user_question, answers, model, tokenizer):\n",
    "  chat = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an intelligent assistant with expertise in evaluating answers for quality, accuracy, and relevance. Your task is to review three answers to the same question and determine which one is the best.\"},\n",
    "    {\"role\": \"system\", \"content\": \"Consider the following criteria to select the best answer:\"},\n",
    "    {\"role\": \"system\", \"content\": \"Accuracy: How correct and factual the information is.\"},\n",
    "    {\"role\": \"system\", \"content\": \"Clarity: How clearly the answer is presented.\"},\n",
    "    {\"role\": \"system\", \"content\": \"After reviewing, state which answer is the best.\"},\n",
    "    {\"role\": \"system\", \"content\": \"For example: ANSWER: The answer [the best answer number] is the best.\"},\n",
    "    {\"role\": \"user\", \"content\": user_question}\n",
    "  ]\n",
    "  chat.extend(answers)\n",
    "\n",
    "  formatted_chat, response = pipe_line(chat, model, tokenizer)\n",
    "      \n",
    "  return formatted_chat, response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YouTube Raora Panthena\n"
     ]
    }
   ],
   "source": [
    "input_chat_with_web_3b, response_with_web_3b = llm_with_web(\"can you give me some information about Youtbuer Raora Panthena?\",Llama323B_model, Llama323B_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_chat_without_web_3b, response_without_web_3b = llm_without_web(\"can you give me some information about Youtbuer Raora Panthena?\",Llama323B_model, Llama323B_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Llama321B_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m input_chat_with_web_1b, response_with_web_1b \u001b[38;5;241m=\u001b[39m llm_with_web(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan you give me some information about Youtbuer 3blue1brown?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43mLlama321B_model\u001b[49m, Llama321B_tokenizer)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Llama321B_model' is not defined"
     ]
    }
   ],
   "source": [
    "input_chat_with_web_1b, response_with_web_1b = llm_with_web(\"can you give me some information about Youtbuer 3blue1brown?\",Llama321B_model, Llama321B_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Llama321B_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m input_chat_without_web_1b, response_without_web_1b \u001b[38;5;241m=\u001b[39m llm_without_web(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan you give me some information about Youtbuer 3blue1brown?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43mLlama321B_model\u001b[49m, Llama321B_tokenizer)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Llama321B_model' is not defined"
     ]
    }
   ],
   "source": [
    "input_chat_without_web_1b, response_without_web_1b = llm_without_web(\"can you give me some information about Youtbuer 3blue1brown?\",Llama321B_model, Llama321B_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Gemma22b_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m input_chat_with_web_Gemma22b, response_with_web_Gemma22b \u001b[38;5;241m=\u001b[39m llm_with_web(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan you give me some information about Youtbuer 3blue1brown?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43mGemma22b_model\u001b[49m, Gemma22b_tokenizer)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Gemma22b_model' is not defined"
     ]
    }
   ],
   "source": [
    "input_chat_with_web_Gemma22b, response_with_web_Gemma22b = llm_with_web(\"can you give me some information about Youtbuer 3blue1brown?\",Gemma22b_model, Gemma22b_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information about Youtbuer Raora Panthena\n",
      "\n",
      "After performing the search, I would provide the requested information in the ANSWER section. Since I can't perform real-time web searches, I'll simulate a response based on the information typically available up to my knowledge cutoff date:\n",
      "\n",
      "ANSWER: Youtbuer Raora Panthena appears to be a name that may not be widely recognized or could be a misspelling or a fictional character. If you are looking for information on a real person, a business, or a cultural reference, please ensure the name is spelled correctly or provide additional context. If this is a character from a book, movie, or other media, please specify the source for accurate information.\n",
      "\n",
      "If you have more details or context, I can attempt to provide a more precise answer.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_chat_with_web_Phi35mini, response_with_web_Phi35mini = llm_with_web(\"can you give me some information about Youtbuer Raora Panthena?\",Phi35mini_model, Phi35mini_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are an assistant with access to a 'web search' tool that helps you find recent or specific information online. Use the following response structure to indicate whether you need to perform a web search or if you have enough information to answer directly<|end|>\n",
      "<|system|>\n",
      "SEARCH REQUEST: When you need additional information to answer a question accurately, output SEARCH REQUEST: [query]. For example: SEARCH REQUEST: latest Canadian election results<|end|>\n",
      "<|system|>\n",
      "ANSWER: When you have the information to answer the question, output ANSWER: [your response]. For example: ANSWER: The recent Canadian election was won by [winner's name].<|end|>\n",
      "<|system|>\n",
      "Do not provide both a `SEARCH REQUEST` and `ANSWER` at the same time.<|end|>\n",
      "<|user|>\n",
      "can you give me some information about Youtbuer Raora Panthena?<|end|>\n",
      "<|system|>\n",
      "Information about Youtbuer Raora Panthena<|end|>\n",
      "<|system|>\n",
      "Raora Panthera is a female English speaking Virtual YouTuber associated with hololive. She debuted in June 2024 as part of hololive English fourth generation -Justice-, alongside Elizabeth Rose Bloodflame, Gigi Murin and Cecilia Immergreen. The Artist with the God Eyes, Raora Panthera is endowed with investigative and descriptive prowess. Her means of information gathering are diverse ...<|end|>\n",
      "<|system|>\n",
      "The Artist with the God Eyes, Raora Panthera is endowed with investigative and descriptive prowess. Her means of information gathering are diverse, utilizing not only her agility and social skills, but also various social media platforms and other… unique methods. The facial composites she draws based on the information she gathers are ...<|end|>\n",
      "<|system|>\n",
      "Raora Panthera (birthday: May 11)[1] is an artist, musician, and VTuber. She is part of the VTuber group called hololive.[1] Raora created her channel on April 3, 2024. She uploaded her debut video on June 22, 2024.[2] The video was her first video and live stream uploaded to the channel. That same day, she uploaded her first cover.[3] On July 19, 2024, Raora announced that memberships had ...<|end|>\n",
      "<|system|>\n",
      "The Artist with the God Eyes, Raora Panthera is endowed with investigative and descriptive prowess. Her means of information gathering are diverse, utilizing not only her agility and social skills, but also various social media platforms and other… unique methods. The facial composites she draws based on the information she gathers are ...<|end|>\n",
      "<|system|>\n",
      "The Artist with the God Eyes here to capture (you)r hearts! ~-----Fan letters and GiftsAddressPresent for: Raora Panthe...<|end|>\n",
      "<|system|>\n",
      "As seen on The Mission Begins! Raora sleeps in cardboard boxes. Bedtime. Energy drink for breakfast. Thanks for the artwork from the artists. Hibana illustration. Buongiorno~. Time to stretch! Ninomae Ina'nis.<|end|>\n",
      "<|system|>\n",
      "『 X formely Twitter 』https://x.com/raorapanthera『 Hashtags 』╰┈ Live #CiaoRaora╰┈ Fanarts #RaorArt╰┈ Clips #RaraWara ...<|end|>\n",
      "<|system|>\n",
      "Raora Panthera (ラオーラ・パンテーラ) is a female VTuber associated with hololive, debuting as part of its English (EN) branch fourth generation alongside Elizabeth Rose Bloodflame, Gigi Murin and Cecilia Immergreen. She speaks English, Italian, and beginner-level Japanese.<|end|>\n",
      "<|system|>\n",
      "Watch the original stream: 【DEBUT】I've got my eyes on you 🐱 mamma mia #hololiveEnglish #holoJusticehttps://www.youtube.com/watch?v=JW7j8tKMOfYCover song:【CO...<|end|>\n",
      "<|system|>\n",
      "Discussion. Tokyo, JAPAN — COVER Corporation (Minato-ku, Tokyo, Japan, CEO: Motoaki Tanigo) announced the debut of the 4th group of hololive English talents, hololive English -Justice-. Four new talents will be joining the hololive English group - Elizabeth Rose Bloodflame, Gigi Murin, Cecilia Immergreen, and Raora Panthera.<|end|>\n",
      "<|assistant|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(input_chat_with_web_Phi35mini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"can you give me some information about SpaceX Starship Fifth Flight Test?\"\n",
    "\n",
    "chat_with_web_Llama323B, response_with_web_Llama323B = llm_with_web(user_input,Llama323B_model, Llama323B_tokenizer)\n",
    "chat_without_web_Llama323B, response_without_web_Llama323B = llm_without_web(user_input,Llama323B_model, Llama323B_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information about SpaceX Starship Fifth Flight Test\n",
      "\n",
      "After conducting a web search, I found the following information:\n",
      "\n",
      "ANSWER: The SpaceX Starship SN5 was the fifth prototype of the Starship spacecraft, which underwent a high-altitude flight test on May 5, 2020. The test aimed to demonstrate the vehicle's ability to reach a significant altitude and then perform a controlled descent and landing. The SN5 prototype was equipped with three Raptor engines and was launched from SpaceX's Boca Chica facility in Texas.\n",
      "\n",
      "During the test, the Starship SN5 reached an altitude of approximately 150 meters (492 feet) before performing a controlled descent. The landing was successful, and the prototype landed upright at the launch site. This test was a significant milestone in SpaceX's development of the Starship spacecraft, which is designed for missions to the Moon, Mars, and beyond.\n",
      "\n",
      "For more detailed and up-to-date information, please refer to the latest news and SpaceX's official announcements.\n",
      "\n",
      "Please note that my knowledge is based on information available up to early 2023, and I recommend checking the latest sources for the most current information.\n"
     ]
    }
   ],
   "source": [
    "chat_with_web_Phi35mini, response_with_web_Phi35mini = llm_with_web(user_input,Phi35mini_model, Phi35mini_tokenizer)\n",
    "chat_without_web_Phi35mini, response_without_web_Phi35mini = llm_without_web(user_input,Phi35mini_model, Phi35mini_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_without_web_Llama321B, response_without_web_Llama321B = llm_without_web(user_input,Llama321B_model, Llama321B_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = [{\"role\": \"answer1\", \"content\": response_with_web_Llama323B},\n",
    "          {\"role\": \"answer2\", \"content\": response_without_web_Llama323B},\n",
    "          {\"role\": \"answer3\", \"content\": response_with_web_Phi35mini},\n",
    "          {\"role\": \"answer4\", \"content\": response_without_web_Phi35mini},\n",
    "          {\"role\": \"answer5\", \"content\": response_without_web_Llama321B}]\n",
    "\n",
    "chat_evaluate, response_evaluate = evaluate_answer(user_input,answer,Llama323B_model, Llama323B_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I must correct myself. I made a mistake. The correct answer is answer1.\n",
      "\n",
      "ANSWER: The answer 1 is the best. It provides accurate information about the SpaceX Starship Fifth Flight Test, which took place on November 10, 2021, at SpaceX's Starbase facility in Boca Chica, Texas. The test reached an altitude of approximately 33.5 kilometers (21 miles) and flew for around 2 minutes and 40 seconds, but unfortunately, the vehicle did not land vertically and disintegrated upon re-entry, resulting in a failed test.\n"
     ]
    }
   ],
   "source": [
    "print(response_evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = Llama323B_tokenizer(chat_evaluate, return_tensors=\"pt\", add_special_tokens=False)\n",
    "toSave = Llama323B_tokenizer.decode(output['input_ids'][0], skip_special_tokens=True)\n",
    "with open(\"chat_evaluate.txt\", \"w\") as text_file:\n",
    "    text_file.write(toSave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = Llama323B_tokenizer(chat_with_web_Llama323B, return_tensors=\"pt\", add_special_tokens=False)\n",
    "toSave = Llama323B_tokenizer.decode(output['input_ids'][0], skip_special_tokens=True)\n",
    "with open(\"chat_with_web_Llama323B.txt\", \"w\") as text_file:\n",
    "    text_file.write(toSave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Phi35mini_tokenizer(chat_with_web_Phi35mini, return_tensors=\"pt\", add_special_tokens=False)\n",
    "toSave = Phi35mini_tokenizer.decode(output['input_ids'][0], skip_special_tokens=True)\n",
    "with open(\"chat_with_web_Phi35mini.txt\", \"w\", encoding='utf-8')  as text_file:\n",
    "    text_file.write(toSave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Gemma22b_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m Gemma22b_model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Gemma22b_model' is not defined"
     ]
    }
   ],
   "source": [
    "del Gemma22b_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Phi35mini_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Llama323B_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Llama321B_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'Information about SpaceX Starship Fifth Flight Test'},\n",
       " {'role': 'system',\n",
       "  'content': 'The flight test concluded at splashdown 1 hour, 5 minutes and 40 seconds after launch. The entire SpaceX team should take pride in the engineering feat they just accomplished. The world witnessed what the future will look like when Starship starts carrying crew and cargo to destinations on Earth, the Moon, Mars and beyond.'},\n",
       " {'role': 'system',\n",
       "  'content': 'SpaceX launched its enormous Starship rocket for the fifth time ever Oct. 13, on a test flight that featured a mid-air catch of the first-stage Super Heavy booster.'},\n",
       " {'role': 'system',\n",
       "  'content': 'What we covered here. • SpaceX launched Starship, the most powerful rocket ever built, on its fifth test flight. • Liftoff of the Super Heavy rocket booster, topped with the uncrewed Starship ...'},\n",
       " {'role': 'system',\n",
       "  'content': 'Starship flight test 5 was the fifth flight test of a SpaceX Starship launch vehicle. The prototype vehicles flown were the Starship Ship 30 upper-stage and Super Heavy Booster 12.This launch is notable for being the first time an orbital-class rocket has been caught out of mid air. After launching and delivering the Starship upper stage into a suborbital trajectory heading toward a splashdown ...'},\n",
       " {'role': 'system',\n",
       "  'content': 'SpaceX will try on Sunday during its fifth test flight of Starship, the giant next-generation rocket that is the most powerful ever built. NASA is counting on Starship to take astronauts to the ...'},\n",
       " {'role': 'system',\n",
       "  'content': \"SpaceX launched its fifth test flight of its Starship rocket on Sunday and made a dramatic first catch of the rocket's more than 20-story tall booster. The FAA issued SpaceX a license to launch ...\"},\n",
       " {'role': 'system',\n",
       "  'content': 'CNN —. Federal regulators granted SpaceX its long-awaited license to move forward with a fifth uncrewed test launch of Starship, the most powerful rocket system ever constructed. The US Federal ...'},\n",
       " {'role': 'system',\n",
       "  'content': 'SpaceX is hoping that this fifth test flight of its Starship megarocket marks a world first. Follow its progress by hitting watch live at the top of the page. Image source, SpaceX'},\n",
       " {'role': 'system',\n",
       "  'content': \"00:00. 00:00. Oct 13 (Reuters) - SpaceX in its fifth Starship test flight on Sunday returned the rocket's towering first stage booster back to its Texas launch pad for the first time using giant ...\"},\n",
       " {'role': 'system',\n",
       "  'content': \"Today's flight test, which was delayed 25 minutes while SpaceX waited for its launch range to be cleared of boats, marks the second full Starship launch, flight, and return to Earth.\"}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_search(\"Information about SpaceX Starship Fifth Flight Test\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[{\"role\": system, \"content\": \"You are an assistant with access to a 'web search' tool that helps you find recent or specific information online. Use the following response structure to indicate whether you need to perform a web search or if you have enough information to answer directly\"},\n",
    "    {\"role\": system, \"content\": \"SEARCH REQUEST: When you need additional information to answer a question accurately, output SEARCH REQUEST: [query]. For example: SEARCH REQUEST: latest Canadian election results\"},\n",
    "    {\"role\": system, \"content\": \"ANSWER: When you have the information to answer the question, output ANSWER: [your response]. For example: ANSWER: The recent Canadian election was won by [winner's name].\"},\n",
    "    {\"role\": system, \"content\": \"Do not provide both a `SEARCH REQUEST` and `ANSWER` at the same time.\"},\n",
    "    {\"role\": user, \"content\": \"can you give me some information about SpaceX Starship Fifth Flight Test?\"},\n",
    "    {'role': system, 'content': 'Information about SpaceX Starship Fifth Flight Test'},\n",
    "    {'role': system, 'content': 'The flight test concluded at splashdown 1 hour, 5 minutes and 40 seconds after launch. The entire SpaceX team should take pride in the engineering feat they just accomplished. The world witnessed what the future will look like when Starship starts carrying crew and cargo to destinations on Earth, the Moon, Mars and beyond.'},\n",
    "    {'role': system, 'content': 'SpaceX launched its enormous Starship rocket for the fifth time ever Oct. 13, on a test flight that featured a mid-air catch of the first-stage Super Heavy booster.'},\n",
    "    {'role': system, 'content': 'What we covered here. • SpaceX launched Starship, the most powerful rocket ever built, on its fifth test flight. • Liftoff of the Super Heavy rocket booster, topped with the uncrewed Starship ...'},\n",
    "    {'role': system, 'content': 'Starship flight test 5 was the fifth flight test of a SpaceX Starship launch vehicle. The prototype vehicles flown were the Starship Ship 30 upper-stage and Super Heavy Booster 12.This launch is notable for being the first time an orbital-class rocket has been caught out of mid air. After launching and delivering the Starship upper stage into a suborbital trajectory heading toward a splashdown ...'},\n",
    "    {'role': system, 'content': 'SpaceX will try on Sunday during its fifth test flight of Starship, the giant next-generation rocket that is the most powerful ever built. NASA is counting on Starship to take astronauts to the ...'},\n",
    "    {'role': system, 'content': \"SpaceX launched its fifth test flight of its Starship rocket on Sunday and made a dramatic first catch of the rocket's more than 20-story tall booster. The FAA issued SpaceX a license to launch ...\"},\n",
    "    {'role': system, 'content': 'CNN —. Federal regulators granted SpaceX its long-awaited license to move forward with a fifth uncrewed test launch of Starship, the most powerful rocket system ever constructed. The US Federal ...'},\n",
    "    {'role': system, 'content': 'SpaceX is hoping that this fifth test flight of its Starship megarocket marks a world first. Follow its progress by hitting watch live at the top of the page. Image source, SpaceX'},\n",
    "    {'role': system, 'content': \"00:00. 00:00. Oct 13 (Reuters) - SpaceX in its fifth Starship test flight on Sunday returned the rocket's towering first stage booster back to its Texas launch pad for the first time using giant ...\"},\n",
    "    {'role': system, 'content': \"Today's flight test, which was delayed 25 minutes while SpaceX waited for its launch range to be cleared of boats, marks the second full Starship launch, flight, and return to Earth.\"}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
